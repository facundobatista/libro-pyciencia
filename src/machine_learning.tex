
% Copyright 2020-2024 Facundo Batista y Manuel Carlevaro
% Licencia CC BY-NC-SA 4.0
% Para más info visitar https://github.com/facundobatista/libro-pyciencia/

%% Ver:
% https://arxiv.org/abs/2310.10368
%%
 \chapter{Aprendizaje automático} \label{ch:machine}   
\begin{wraptable}{r}{5cm}
\begin{modulesinfo}
\begin{center}
{\small
    \begin{tabular}{l r}
        \toprule
        \textbf{Módulo} & \textbf{Versión} \\
        \midrule
        Keras & 3.6.0 \\
        Matplotlib & 3.9.2 \\
        NumPy & 1.26.4 \\
        scikit-learn & 1.5.2 \\
        tensorflow & 2.18.0 \\
        tqdm & 4.66.6 \\
        \bottomrule
    \end{tabular}
    \vspace{0.75em}
    
    \href{https://github.com/facundobatista/libro-pyciencia/tree/master/código/machine_learning/}{Código disponible}
}
\end{center}
\end{modulesinfo}
\end{wraptable}

En el contexto de la inteligencia artificial coexisten diversas metodologías tales como sistemas expertos, agentes racionales, procesamiento del lenguaje natural, visión de computadoras, robótica, y aprendizaje de máquinas o \textit{machine learning} (ML). Particularmente esta ultima metodología ha mostrado un desarrollo impresionante de aplicaciones en los últimos años, debido principalmente al avance en los procesadores de cálculo especializados (GPUs\footnote{\textit{Graphics processing unit}, unidad de procesamiento gráfico.} y TPUs\footnote{\textit{Tensor processing unit}, unidad de procesamiento tensorial.}) y a la existencia sistematizada de grandes cantidades de información (\textit{big data}).

 Entre las diferentes metodologías de ML se encuentran las redes neuronales (o NN por su sigla en inglés), cuyos orígenes se remontan al trabajo de McCulloch y Pitts de 1943 \cite{McCulloch1943}, quienes intentaron modelar las redes de neuronas en el cerebro mediante redes de cálculo computacional. Existen numerosas topologías o ``arquitecturas''\footnote{Ver \href{https://www.asimovinstitute.org/neural-network-zoo/}{\textit{The Neural Network Zoo}} (en inglés).} de estas redes, que se especializan para realizar diferentes tareas de como ajuste de funciones, clasificación, identificación de patrones, detección de agregados (``\textit{clustering}''), etc.

Analizaremos aquí un modelo simple de red del tipo \textit{feedforward} (o de avance o propagación directa), en las cuales las conexiones entre distintas neuronas son solo en una dirección, formando de este modo un grafo acíclico entre las entradas y las salidas. Cada nodo de la red computa una función de sus entradas y pasa el resultado a las entradas de los nodos siguientes, sin generar ciclos. Por otra parte, existen otros tipos de redes como las recurrentes, en las cuales las entradas de los nodos se retroalimentan con sus propias salidas (este tipo de redes es apropiado para el ajuste de series temporales, por ejemplo).


\begin{figure}[t]
    \begin{center}
    \includegraphics[width=0.8\textwidth]{Chapters/machine_learning/figs/red.pdf}
\end{center}
\caption{Representación de la estructura de una red \textit{feedforward} multicapa.}
\label{fig:red}
\end{figure}

\section{Nodos, pesos y funciones de activación}
Una red neuronal constituye un grafo en el que los nodos representan las ``neuronas'', que son unidades de cálculo inspiradas en las neuronas biológicas. Estas últimas están conectadas unas a otras mediante axones y dendritas por medio de enlaces sinápticos que realizan la transmisión de impulsos nerviosos. Este proceso es el que se simula en las redes neuronales artificiales, en las que los nodos de cada capa están conectados a los nodos de la capa siguiente de la red a través de ``pesos'' que representan la intensidad de la conexión sináptica entre los nodos. Una red neuronal artificial calcula una función de los valores de entrada hacia los nodos de salida, utilizando estos pesos como parámetros de dicha función. Un esquema de esta estructura se ve en la Figura \ref{fig:red}, en la que se muestra la capa de nodos de entrada (en azul), varias capas intermedias (u ``ocultas'', en verde), y una capa de nodos de salida (en rojo). Las neuronas de cada capa están densamente conectadas con las capas vecinas.

Cada nodo (o neurona) en la red computa una suma ponderada de las entradas de sus nodos predecesores, y a este resultado le aplica una función no lineal para producir la salida, tal como se representa en la Figura \ref{fig:nodo}. Si denotamos por $y_j$ la salida del nodo $j$, y $\omega_{i,j}$ el peso correspondiente a la conexión entre el nodo predecesor $i$ y el $j$, la salida del nodo $j$ da como resultado:
\[ y_j = g_j\left(\sum_{i=0}^n \omega_{ij} x_i\right) = g_j(z_j) \]
donde $z_j = \sum_{i=0}^n \omega_{ij} x_i$ es la suma ponderada de los $n$ nodos precedentes conectados con el nodo $j_i$, denominado ``valor de activación''. Aquí, $g_j(\cdot)$ es alguna función no lineal denominada ``función de activación''. Es usual asumir que $x_0 = 1$ por lo que $\omega_{0j}$ es un término de \textit{bias} o sesgo, y es un parámetro que permite que los nodos de la red aprendan aún cuando todas las entradas sean nulas.

\begin{figure}[t]
    \begin{center}
    \includegraphics[width=0.8\textwidth]{Chapters/machine_learning/figs/nodo.pdf}
\end{center}
\caption{a) Esquema de un nodo o ``neurona''. b) Esquema con la separación de operaciones indicando explícitamente el valor de preactivación $z_j$.}
\label{fig:nodo}
\end{figure}

Si bien tanto la transformación lineal como la posterior evaluación de la función de activación son cómputos que se realizan en una neurona, es posible considerar un nodo con su correspondiente función de activación no lineal como dos nodos computacionales, uno que realiza la transformación lineal $z_j = \bm{\omega}^{\intercal} \cdot \bm{x}$, siendo $\bm{\omega}$ el vector que representa los pesos que conectan las entradas $\bm{x} = [x_0, x_1, \ldots, x_n]$ del nodo $j$ (aquí denotamos las cantidades vectoriales con letras en negrita). En el ejemplo que desarrollaremos a continuación, usaremos este esquema desacoplado de cálculo, lo que simplificará la representación computacional de los nodos.

El hecho de que la función de activación sea no lineal es de central importancia, porque si fuese lineal, cualquier composición de nodos solo podría representar una función lineal. La no linealidad de $g_j$ es lo que permite que redes suficientemente grandes puedan representar funciones arbitrarias\footnote{Ver el teorema de aproximación universal \cite{cybenko1989, hornik1991,leshno1993}.}. Existe una variedad de funciones de activación que se usan con diferentes propósitos. Adicionalmente, tienen un impacto significativo en la velocidad de aprendizaje, factor que es uno de los principales criterios para su elección. Entre las más utilizadas están:
\begin{itemize}
    \item La función logística o sigmoidea:
        \[\sigma(x) = \frac{1}{1 + e^{-x}} \]
    \item La función lineal rectificada (o ReLU, por su sigla en inglés \textit{rectified linear unit}):
        \[ \text{ReLU}(x) = \max(0, x) \]
    \item La función \textit{softplus}, que es una versión suavizada de la ReLU:
        \[ \text{softplus}(x) = \log(1 + e^x) \]
        y cuya derivada es la función sigmoidea.
    \item La función tangente hiperbólica: 
        \[ \tanh(x) = \frac{e^{2x} - 1}{e^{2x} + 1} \]
\end{itemize}


\begin{figure}[t]
    \begin{center}
    \includegraphics[width=1.0\textwidth]{Chapters/machine_learning/figs/activacion.pdf}
\end{center}
\caption{Funciones de activación: a) sigmoidea, b) ReLU y softplus y c) tangente hiperbólica.}
\label{fig:factivacion}
\end{figure}

La Figura \ref{fig:factivacion} muestra las representaciones gráficas de estas funciones. Se puede apreciar que tanto la sigmoidea como la tangente hiperbólica acotan el recorrido a un intervalo finito: $(0, 1)$ para el caso de la sigmoidea y $(-1, 1)$ para la tanh. Un comporamiento diferente tienen ReLU y softplus, ya que estas funciones no están acotadas. En particular, la función softplus tiene derivada continua en $x = 0$, a diferencia de ReLU. En todos los casos, las funciones son monótonamente crecientes, por lo que en todos sus dominios las derivadas correspondientes son positivas.

Una función de activación particular, dado que se utiliza casi exclusivamente en la capa de salida, es la \textit{softmax} o función exponencial normalizada. Esta función es una generalización de la función logística que convierte un vector de $k$ números reales en una distribución de probabilidad de $k$ eventos discretos. Específicamente, si la entrada es un vector $\bm{z} = [z_1, z_2, \ldots, z_k]$ que representa los valores de activación de los $k$ nodos en una capa dada, la función de activación \textit{softmax} para la salida $i$-ésima es:
\[ \sigma(\bm{z}) = \frac{e^{z_i}}{\sum_{j=1}^k e^{z_j}}, \quad \forall i \in \{1, 2, \ldots, k\} \]

Al utilizar un esquema desacoplado de cálculo, una capa que implementa solo la función \textit{softmax} no requiere pesos que deban ajustarse, ya que solo transforma un vector de valores reales en probabilidades.

Una forma general de abordar el tratamiento matemático que realiza una red \textit{feedforward} es la de considerar la red como grafo de cálculo o de ``flujo de datos'', esto es, un grafo donde cada nodo representa un cálculo elemental y las uniones entre los nodos representan la relación de entrada/salida de los diferentes nodos. La Figura \ref{fig:flujo} muestra, a la izquierda, el flujo de cálculos que se realiza a partir de las entradas $x_1$ y $x_2$ (en azul) y que realizan los nodos $3$, $4$ y $5$ utilizando los pesos $\omega_{ij}$ (en rojo), dando como resultado el valor $y$. A la derecha de la Figura \ref{fig:flujo} se representa la red en su forma simplificada habitual.


\begin{figure}[t]
    \begin{center}
    \includegraphics[width=1.0\textwidth]{Chapters/machine_learning/figs/flow.pdf}
    %\includegraphics[scale=1.0]{Chapters/machine_learning/figs/flow.pdf}
\end{center}
\caption{Flujo del cálculo de operaciones matemáticas en una red ``\textit{feedforward}''. A la izquierda, el detalle para una red con dos neuronas de entrada $(x_1, x_2)$, dos neuronas en la capa oculta, con funciones de activación $g_3$ y $g_4$, y una neurona en la capa de salida con función de activación $g_5$ que produce la predicción $y$. A la derecha, la forma simplificada usual de representación.}
\label{fig:flujo}
\end{figure}


\section{Aprendizaje}

El procedimiento por el cual se modifican los valores de los pesos de una red neuronal, con el propósito de minimizar el error en sus predicciones, se denomina ``aprendizaje''. Este procedimiento se inicia con un conjunto de datos de entrada a los que se expone la red, y a partir de las predicciones que obtiene de estas entradas se genera una retroalimentación que pueden clasificarse, en general, en tres tipos:
\begin{itemize}
    \item \textbf{Aprendizaje supervisado}. Cada valor de entrada se acompaña de la correspondiente salida conocida (que usualmente se denomina ``etiqueta''), y la red aprende una función que mapea la entrada con la salida. Este será el caso que abordaremos a continuación, en la que cada entrada es una imagen y la correspondiente salida es un dígito decimal.
    \item \textbf{Aprendizaje no supervisado}. En este caso, la red aprende a detectar patrones en las entradas sin la especificación de la retroalimentación. Uno de los ejemplos más usuales de este caso el el agrupamiento o \textit{clustering}.
    \item \textbf{Aprendizaje por refuerzo}. Aquí se utiliza un sistema de refuerzo, por lo general un premio y castigo. Esta forma de aprendizaje es la típica de redes que aprenden a jugar, obteniendo un premio al ganar el juego o un castigo al perderlo. De este modo, la red aprende de qué forma puede actuar para ganar más premios en el futuro.
\end{itemize}

Dado que este aprendizaje representa formalmente un proceso de optimización, podría usarse en principio cualquier algoritmo con ese propósito (por ejemplo, un algoritmo genético \cite{gupta1999, mirjalili2019, lanham2023}). Sin embargo, en la práctica el método predominante para el entrenamiento de redes neuronales es el del descenso del gradiente (o alguna variante). En particular, examinaremos el descenso estocástico del gradiente (SGD por su sigla en inglés), que es un método iterativo que permite optimizar una función suficientemente suave (como las que mencionamos como funciones de activación y transformaciones lineales) por medio de una aproximación en la que se reemplaza el gradiente de la función calculado sobre el conjunto completo de datos por una estimación obtenida a partir de un subconjunto elegido al azar de dichos datos. Esta estrategia de optimización permite abordar problemas de alta dimensión (como el conjunto $\bm{\omega}$ de parámetros de una red neuronal) disminuyendo el costo computacional, pagando el precio de una menor velocidad de convergencia. Una forma muy utilizada de implementar el método SGD es a través del algoritmo de propagación hacia atrás, o \textit{backpropagation}, que describiremos a continuación.

Formalmente, el entrenamiento para el caso del aprendizaje supervisado se puede proponer del siguiente modo: dado el conjunto de entrenamiento con $N$ muestras
\[ X = \{ (\bm{x}_1,\bm{y}_1), (\bm{x}_2, \bm{y}_2), \cdots, (\bm{x}_n, \bm{y}_N) \} \]
donde cada par fue generado por una función desconocida $\bm{y} = f(\bm{x})$, determinar una función $\hat{f}(X, \bm{\omega})$ que aproxime a $f$. Naturalmente, tanto $\bm{x}_i$ como $\bm{y}_i$ son usualmente cantidades vectoriales. Con este fin, se define una ``función costo''\footnote{Es usual referirse a la función costo también como función de pérdida (\textit{loss}) o función objetivo.}, $C$, que resulta de alguna medida de la diferencia entre los valores $\hat{\bm{y}}_i = (y_1^L, y_2^L, \ldots, y_{m_L}^L)$ que predice la red para una determinada entrada $\bm{x}_i$ y parámetros de pesos y sesgos $\bm{\omega}$. Aquí, $L$ es el número de capas de la red ($L$ es el índice de la capa de salida) y $m_L$ es la cantidad de nodos que tiene la capa $L$. Claramente, la idea es que durante el aprendizaje de la red, los valores de esta función disminuyan progresivamente, dado que idealmente si las predicciones coinciden con los valores reales, la ``distancia'' entre ellas será nula. Según el problema que abordamos con la red (regresión, clasificación, salidas discretas o continuas), pueden elegirse distintas opciones para $C$, por ejemplo el valor absoluto de la diferencia entre el valor predicho y el valor verdadero $\norm{\bm{y} - \hat{\bm{y}}}$ (conocida usualmente como la norma $L^1$), el error cuadrático $\norm{\bm{y} - \hat{\bm{y}}}^2$, o la función de costo $0/1$ que devuelve un valor 1 si la predicción es incorrecta y es útil para salidas con valores discretos $0 \text{ si } y = \hat{y}, \text{ si no } 1$. 

La función $\hat{f}$ que mencionamos anteriormente depende los valores de las entradas del conjunto de entrenamiento, $x$, y también de los valores de los pesos y sesgos $\bm{\omega}$. No obstante, durante el aprendizaje los valores tanto de las entradas como las etiquetas están fijos, por lo que solo tenemos la posibilidad de minimizar la función costo a través de $\bm{\omega}$. En lo siguiente, adoptaremos como $C$ la función error cuadrático medio\footnote{En el ejemplo de aplicación utilizaremos como función costo la función de entropía cruzada o \textit{crossentropy}.}:
\begin{equation} C(X, \bm{\omega}) = \frac{1}{2n} \sum_{i=1}^N \norm{\bm{\hat{y}}_i - \bm{y}_i}^2 \label{ec:costo} \end{equation}

La suma se realiza sobre cada caso individual del conjunto de entrenamiento y $\norm{\cdot}$ es la norma $L^2$ o euclídea. Esta elección de la función costo según la expresión \eqref{ec:costo} cumple con una condición necesaria para poder utilizar el algoritmo de \textit{backpropagation}, esto es, que $C$ debe ser \textit{aditiva}, ya que de este modo podemos escribir la función costo como un promedio de funciones costo para muestras de entrenamiento individuales $C(\bm{x}_i)$, lo que nos permitirá calcular las derivadas parciales, y obtener luego el gradiente $\partial C / \partial \bm{\omega}$ a partir de promedios sobre las muestras de entrenamiento.

Si bien esta función depende de los valores de $\bm{y}_i$, recordemos que estos valores están fijos durante el entrenamiento, al igual que los valores de las entradas correspondientes $\bm{x}_i$, por lo que estrictamente los valores de $C$ quedan determinados por la elección de los pesos $\bm{\omega}$. De este modo, minimizar la función consiste en utilizar el descenso del gradiente para que iterativamente generemos una sucesión de valores de $\bm{\omega}$ que disminuyan el valor de $C$:
\begin{equation}\bm{\omega}^{t+1} = \bm{\omega}^t - \eta \frac{\partial C(X, \bm{\omega}^t)}{\partial \bm{\omega}}
\label{eq:actpesos}
\end{equation}

donde $\bm{\omega}^t$ denota los parámetros de la red neuronal en la iteración $t$ del descenso del gradiente. $\eta$ se denomina ``tasa de aprendizaje'' y determina el tamaño del paso que se da en la dirección del descenso del gradiente y por lo tanto condiciona la forma en que converge la minimización. El valor de $\eta$ debe realizarse cuidadosamente para evitar inestabilidades en el proceso de aprendizaje, y usualmente está definido en el rango $0 < \eta < 1$.

Dado que la función costo se puede descomponer en una suma sobre términos de costo o error para cada para individual de entrada salida $(\bm{x}_i, \bm{y}_i)$, la derivada se puede calcular para cada par entrada/salida individualmente y luego combinar estos términos al final, ya que la derivada de una suma de funciones es la suma de las derivadas de cada función:
\[ \frac{\partial C(X, \bm{\omega})}{\partial \omega_{ij}^k} = \frac{1}{N} \sum_{d=1}^N \frac{\partial}{\partial \omega_{ij}^k} \left(\dfrac{1}{2}(\bm{\hat{y}}_d - \bm{y}_d)^2\right) = \frac{1}{N} \sum_{d=1}^N \frac{\partial C_d}{\partial \omega_{ij}^k} \]
donde $\omega_{ij}^k$ el el peso (o sesgo) para el nodo $j$ de la capa $l_k$ del nodo de entrada $i$ en la capa $l_{k-1}$. De este modo, con el propósito de derivar el algortimo de \textit{backpropagation} vamos a considerar solo un par de entrada/salida. Luego de esta derivación, la forma general para todos los pares de entrada/salida del conjunto $X$ puede ser generada combinando los gradientes individuales. Así, la función costo que utilizaremos es:
\[ C = \frac{1}{2}\norm{\bm{\hat{y}} - \bm{y}}^2 \]
donde omitimos el subíndice $d$ en $C_d$, $\bm{\hat{y}}_d$ y $\bm{y}$ por simplicidad.

La derivación del algoritmo de \textit{backpropagation} comienza aplicando la regla de la cadena a la derivada parcial de la función costo
\[ \frac{\partial C}{\partial \omega_{ij}^k} = \frac{\partial C}{\partial z_j^k} \frac{\partial z_j^k}{\partial \omega_{ij}^k} \]
donde $z_j^k$ es el valor de activación del nodo $j$ de la capa $k$ antes de pasar por la función de activación para generar la salida $y_j^k$. Esta descomposición de la derivada parcial establece que el cambio en la función costo debido a un peso es el producto del cambio de la función $C$ debido a la activación $z_j^k$ multiplicado por el cambio en la activación $z_j^k$ debido al peso $\omega_{ij}^k$. Generalmente se llama ``error'' al primer factor de la expresión anterior, y se denota por
\[ \delta_j^k \equiv \frac{\partial C}{\partial z_j^k} \]

El segundo factor se puede calcular a partir de la definición del valor de activación:
\[ \frac{\partial z_j^k}{\partial \omega_{ij}^k} = \frac{\partial}{\partial \omega_{ij}^k} \left(\sum_{l=0}^{m_{k-1}} \omega_{lj}^k y_l^{k-1}\right) = y_i^{k-1} \]
siendo $m_{k-1}$ la cantidad de nodos en la capa $k-1$. Entonces, la derivada parcial de la función costo $C$ con respecto de un peso $\omega_{ij}^k$ es 
\[ \frac{\partial C}{\partial \omega_{ij}^k} = \delta_j^k y_i^{k-1} \]

Se puede ver entonces que la derivada parcial respecto a un peso es el producto del término de error $\delta_j^k$ del nodo $j$ en la capa $k$, y de la salida $y_i^{k-1}$ del nodo $i$ de la capa $k-1$. Esto resulta bastante intuitivo porque $\omega_{ij}^k$ conecta la salida del nodo $i$ de la capa $k-1$ con la entrada del nodo $j$ de la capa $k$ en el grafo computacional.

Comenzamos con el cálculo de errores de la última capa ($L$), que pueden ser evaluados directamente a partir de la ``distancia'' entre los valores predichos por la red y los correspondientes del conjunto de entrenamiento $X$. Para el nodo $j$ en la capa de salida cuya función de activación es $g_o(z_j^L)$, tenemos:
\[ C_j = \frac{1}{2}(\hat{y}_j - y_j)^2 = \frac{1}{2} \left(g_o(z_j^L) - y_j\right)^2 \]

Aplicando la derivada parcial y usando la regla de la cadena resulta:
\[ \delta_j^L = (g_o(z_j^L) - y_j) g_o'(z_j^L) = (\hat{y}_j - y_j) g_o'(z_j^L) \]
donde como es usual, $g'$ es la derivada de $g$. La derivada parcial de $C$ con respecto a un peso de la capa final es, entonces,
\[ \frac{\partial C_j}{\partial \omega_{ij}^L} = \delta_j^L z_i^{L-1} = (\hat{y}_j - y_j) g_o'(z_i^L) y_i^{L-1} \]

Ahora podemos empezar a propagar hacia atrás los errores de la última capa, y para ello volvemos a utilizar la regla de la cadena para la derivada de funciones multivariadas. El término del error $\delta_k^k$ en la capa $1 \leq k \leq L$ es 
\[ \delta_j^k = \sum_{l = 1}^{m_{k+1}} \frac{\partial C}{\partial z_l^{k+1}} \frac{\partial z_l^{k+1}}{\partial z_j^k} \]
donde $l$ va desde 1 hasta $m_{k+1}$ (el número de nodos de la capa siguiente). Notar que debido a que la entrada de sesgo $y_0^k$ correspondiente a $\omega_{0j}^{k+1}$ es fijo, su valor no depende de las salidas de las capas previas, y por lo tanto $l$ no toma el valor cero. Insertando el término de error $\delta_l^{k+1}$ obtenemos la siguiente ecuación:
\[ \delta_j^k = \sum_{l=1}^{m_{k+1}} \delta_l^{k+1} \frac{ \partial z_l^{k+1}}{\partial z_j^k} \]

A partir de la definición del valor de activación:
\[ z_l^{k+1} = \sum_{j=1}^{m_k} \omega_{jl}^{k+1} g(z_j^k) \]
donde $g(\cdot)$ es la función de activación de las capas ocultas, tenemos
\[ \frac{\partial z_l^{k+1}}{\partial z_j^k} = \omega_{jl}^{k+1} g'(z_j^k) \]

Reemplazando esta expresión en la ecuación previa obtenida para $\delta_j^k$, resulta la derivada parcial de la función costo con respecto a un peso en las capas ocultas $\omega_{ij}^k$ para $1 \leq k < L$:
\[ \frac{\partial C}{\partial \omega_{ij}^k} = \delta_j^k y_i^{k-1} = g'(z_j^k) y_i^{k-1} \sum_{l=1}^{m_{k+1}} \omega_{jl}^{k+1} \delta_l^{k+1} \] 

Esta ecuación es el motivo del nombre del algoritmo de aprendizaje. El error $\delta_j^k$ en la capa $k$ depende de los errores $\delta_l^{k+1}$ de la capa siguiente $k+1$. De este modo, los errores se propagan hacia atras desde la última capa hacia la primera. El algoritmo comienza entonces calculando los errores de la última capa a partir de la salida predicha por la red $\hat{y}_j = g_o(z_j^L)$ y del valor de entrenamiento $y_j$. A partir de aquí, los términos de error de la capa previa son calculados realizando una suma de los errores recién calculados ponderada por los pesos $\omega_{jl}^{k+1}$ de los términos de error de la capa siguiente y escalados por $g'(z_j^k)$, y esto se repite hasta que se alcanza la primera capa.

Esta propagación hacia atrás de los errores es muy similar a la propagación hacia adelante que calcula la predicción de la red. Por esto, el cálculo de la salida de la red se suele llamar la ``fase de propagación hacia adelante'', mientras que el cálculo de los errores y derivadas se denomina usualmente ``fase de propagación hacia atrás'', o \textit{backpropagation}. Durante la fase de avance, las entradas se combinan repetidamente desde la primer capa hasta la última por medio de las sumas ponderadas por los pesos $\omega_{ij}^k$ y las funciones de activación $g(x)$ y $g_o(x)$. En la fase de retroceso, las ``entradas'' son los términos de error de la capa final, que son repetidamente recombinados desde la última capa hacia la primera mediante sumas ponderadas por los pesos $\omega_{ij}^{k+1}$ y transformados por los factores de escala no lineales $g_o'(z_j^L)$ y $g'(z_j^k)$.

Con las expresiones obtenidas para el cálculo del gradiente de $C$ con respecto de $\bm{\omega}$, podemos realizar la secuencia de actualizaciones de los pesos dada por la ecuación \eqref{eq:actpesos}. Esta actualización no se realiza calculando el gradiente completo sobre todo el conjunto de entrenamiento $X$ simultáneamente, sino que se realiza una estimación del gradiente utilizando un subconjunto de $X$ elegido aleatoriamente, en lo que se denomina un \textit{minibatch}. El uso de \textit{minibatchs} otorga eficiencia al método, dado que permiten un entrenamiento más rápido al calcular el gradiente y actualizar los pesos solo con una parte de los datos. Además, al promediar los gradientes de múltiples ejemplos, reduce el ruido y mejora la estabilidad del proceso de aprendizaje. No obstante, este método puede afectar a la precisión final de la red, ya que la actualización de los pesos se basa en una aproximación del gradiente total. El tamaño de la muestra que compone el minibatch es un parámetro importante que se debe ajustar para obtener un buen rendimiento.

Una vez que el conjunto $X$ se particiona en subconjuntos aleatorios de muestras en \textit{minibatch}, se llama una ``era'' a la secuencia de actualizaciones de los pesos en cada \textit{minibatch}, hasta que se recorre el conjunto completo de aprendizaje. Luego, se iteran sucesivas eras hasta que la función costo alcanza un valor suficientemente bajo. En el ejemplo siguiente analizaremos una implementación práctica del algoritmo de \textit{backpropagation} para el entrenamiento de una red \textit{feedforward}. 


\section{Ejemplo de red usando NumPy}

\begin{figure}
    \begin{center}
    \includegraphics[width=0.75\textwidth]{Chapters/machine_learning/figs/MnistEx.png}
\end{center}
    \caption{Ejemplo de imágenes del conjunto MNIST. Fuente: \href{https://commons.wikimedia.org/w/index.php?curid=132282871}{Wikimedia Commons}.}
    \label{fig:mnist}
\end{figure}

Vamos a poner en código los conceptos desarrollados para la red de propagación hacia adelante, entrenando una red para que pueda reconocer dígitos escritos a mano. Utilizaremos para ello el conjunto de datos MNIST\footnote{Ver entrada en \href{https://es.wikipedia.org/wiki/Base\_de\_datos\_MNIST}{Wikipedia}. El conjunto MNIST se puede descargar desde \href{https://www.kaggle.com/datasets/oddrationale/mnist-in-csv}{acá}.} que consiste en una colección de \num{60000} imágenes de entrenamiento y \num{10000} imágenes de prueba. Cada imagen tiene una resolución de \numproduct{28 x 28} píxeles en valores que representan una escala de grises en el rango $[0, 255]$. Una muestra de las imágenes que componen el conjunto se puede ver en la Figura \ref{fig:mnist}. 

Como es usual, en las primeras líneas importamos los módulos necesarios para crear clases abstractas (\mip{abc}); para intepretar los argumentos de la línea de comandos (\mip{argparse}); para serializar y guardar objetos (\mip{pickle}); para realizar conteos de frecuencia (\mip{Counter}); los usuales para graficar (\mip{matplotlib}) y para operaciones numéricas (\mip{numpy}); y finalmente para visualizar una barra de progres (\mip{trange}). A continuación establecemos el valor de la semilla del generador de números aleatorios de modo de poder reproducir los resultados.\footnote{Usamos para esto el trigésimo primer \href{https://es.wikipedia.org/wiki/Número\_perfecto}{número perfecto}.}

\pyfile[firstline=3, lastline=13]{Chapters/machine_learning/code/nn-mnist.py}

Comenzamos definiendo la función \mip{load_dataset}, que como su nombre indica será la responsable de leer los datos desde un archivo csv (ver subsección \ref{subs:datosCSV}). Este archivo contiene en cada fila una imagen, la primer columna de la fila es el dígito que representa dicha imagen (valor entre 0 y 9), y las restantes 784 columnas contiene el valor en escala de gris de cada píxel. Esta función devuelve dos arrays de \mip{(N, 1)} y \mip{(N, 784)} en \mip{Y_train} y \mip{X_train}, respectivamente, siendo \mip{N} la cantidad de datos que contiene el \textit{dataset}. El conjunto de entrada (\mip{X_train}) se normaliza antes de devolver ambos arrays.

\pyfile[firstline=16, lastline=26]{Chapters/machine_learning/code/nn-mnist.py}

La estructura de nuestra red consiste en una secuencia de capas que contienen a los nodos separados en dos unidades de cálculo: la que calcula los valores de activación $z_i$ y la que que representa las correspondientes funciones de activación. En este contexto, definimos primero una clase abstracta \mip{Layer} que define los métodos que luego cada clase derivada debe implementar: \mip{forward}, que realiza un paso de propagación hacia adelante, y \mip{backward} que utilizaremos durante la fase de entrenamiento para implementar el algoritmo de \textit{backpropagation}:

\pyfile[firstline=29, lastline=54]{Chapters/machine_learning/code/nn-mnist.py}

Para todas las capas ocultas utilizaremos ReLU como función de activación. Los nodos de esta capa no contienen información sobre los pesos de las conexiones sinápticas, ya que solamente toman como entrada el valor de activación calculado en la capa previa y transforma este valor según la función ReLU. Esto es lo que implementa el método \mip{forward}. Para el cálculo de la propagación hacia atrás del error, esto simplemente es el error de la capa siguiente multiplicado por la derivada de la función ReLU (que es 1 si $x > 0$, y 0 para $x \leq 0$). Este es el cálculo que realiza el método \mip{forward}. 

\pyfile[firstline=57, lastline=68]{Chapters/machine_learning/code/nn-mnist.py}

La clase siguiente permite instanciar capas cuyos nodos están todos conectados con todos los nodos de la capa anterior, y por eso se denomina \mip{Dense}. A diferencia de la capa \mip{ReLU}, esta capa contiene los valores $\omega_{ij}^l$ (\mip{self.W}) que representan los pesos de las conexiones entre los nodos $i$ de la capa $l-1$ con los nodos $j$ de la capa $l$. Por lo tanto esta capa contiene un método adicional (\mip{__init__}) que permite inicializar estos valores (utilizamos para ello el método de inicialización de Xavier\cite{glorot2010}, que asigna valores en un rango razonable de valores obtenidos de una distribución normal con media cero y varianza que depende de la cantidad de conexiones de entrada y salida). Además, en esta capa separamos explícitamente el valor de los sesgos o \textit{bias} (\mip{self.bias}). El método \mip{forward} realiza el cálculo del valor de activación por medio del producto matricial del array con los valores de entrada y los pesos, sumando los valores de los sesgos. Por su parte, el método \mip{backward} no solo calcula el gradiente de la función costo respecto de los pesos, sino que también implementa la actualización de los mismos  con el método del descenso del gradiente incorporando el correspondiente parámetro $\eta$ (\mip{self.learning_rate}).

\pyfile[firstline=71, lastline=96]{Chapters/machine_learning/code/nn-mnist.py}

En nuestro ejemplo, la última capa será una instancia de \mip{Dense}, por lo que su salida consiste en los valores de activación que genera esta clase sin pasar por una función de activación. Llamaremos \textit{logits} a estos valores (o vector logit como se lo utiliza habitualmente), que serán utilizados para predecir el valor numérico de la imagen de entrada como una medida de probabilidad. En este contexto utilizaremos una función de activación softmax para la última capa junto con una función costo del tipo entropía cruzada, o \textit{crossentropy}, que se usa frecuentemente para estimar la diferencia entre dos distribuciones de probabilidad y se basa en el concepto de entropía de la información propuesta por Shannon \cite{shannon1948}.

Llamando $l_i$ a la componente $i$-ésima del vector logit, y $p_i$ al valor correspondiente luego de pasar por la función softmax, la función costo es:
\[ C(\bm{y}, \bm{l}) = -\sum_i {y_i \left[l_i + \log\left(\sum_j e^{l_j}\right)\right]} \]

Esta expresión se simplifica si codificamos las etiquetas (digitos entre cero y nueve) en forma de un vector binario que tiene un 1 en la posición que corresponde a cada dígito (conocido también como \textit{one-hot encoding}, o OHE). Por ejemplo, si el valor de la etiqueta es 4, la codificamos en forma OHE como el vector (\mip{0, 0, 0, 0, 1, 0, 0, 0, 0, 0}), es decir, $y_l = 1$ para $l = 4$ y cero en otro caso. De este modo, combinamos el cálculo de la función softmax sobre el vector logit de la última capa con la función de pérdida de \textit{crossentropy}, y obtenemos para cada nodo $j$ de la última capa:
\[ C_j = -l_j + \log \left(\sum_i e^{l_i}\right) \]

La función \mip{softmax_crossentropy_with_logits} implementa este cálculo, devolviendo un array (\mip{xentropy}) que contiene los valores de $C_j$ para cada nodo $j$ de la última capa. El correspondiente cálculo del gradiente de esta función costo se realiza en la función\\ \mip{grad_softmax_crossentropy_with_logits}:

\pyfile[firstline=99, lastline=117]{Chapters/machine_learning/code/nn-mnist.py}

Con todo lo anterior ya tenemos lo necesario para crear una red. Esto lo hacemos a partir de la clase \mip{Network}, que básicamente consiste en una secuencia (en forma de lista) sobre la que actuarán los correspondientes métodos \mip{_forward}, para propagar los cálculos hacia adelante a partir de los datos de entrada $X$, \mip{predict} para obtener la predicción de la red ante una entrada determinada, el método \mip{train} para entrenar la red a partir de pares $(X, Y)$, implementando \textit{backpropagation}, y dos métodos más: \mip{dump} para guardar los parámetros de una red entrenada y \mip{load} para recuperar dichos parámetros desde un archivo en disco y crear una red operativa para realizar predicciones.

Declaramos la clase \mip{Network} junto con el método \mip{__init__}, que recibe una lista (\mip{layers}) que contiene objetos instanciados a partir de las clases \mip{ReLU} y \mip{Dense}. A continuación, el método \mip{_forward} calcula los valores de activación de cada capa, secuencialmente a partir de la capa de entrada, y devuelve estos valores en el array \mip{activations}:

\pyfile[firstline=120, lastline=137]{Chapters/machine_learning/code/nn-mnist.py}

El método \mip{predict} recibe una entrada $X$ y propaga los cálculos hacia adelante en la red hasta la última capa, donde se calcula el vector logit. La predicción de la red resulta de la posición de este vector que tiene el máximo valor (recordar que usamos OHE para codificar los dígitos, por lo que si el valor máximo del vector logit ocurre en la sexta posición, la predicción es el dígito 5). No hace falta aplicar una función de activación sobre los logits, como softmax, dado que por ser una función estrictamente no negativa, solo realiza un cambio de escala pero no altera la posición del máximo:

\pyfile[firstline=139, lastline=146]{Chapters/machine_learning/code/nn-mnist.py}

El método \mip{train} realiza secuencialmente los pasos que detallamos del algoritmo \textit{backpropagation}. Recibe como argumentos una entrada $X$ y su correspondiente etiqueta (el valor del dígito al que corresponde la imagen) $y$. En primer lugar realiza el avance hacia adelante en la red de los cálculos que llevan desde la entrada a las activaciones de la última capa (vector logits). Luego de esto le agregamos al principio el propio array $X$ para tenerlo como entrada de la primera capa. A continuación obtenemos el array \mip{loss}, que corresponde al valor del costo de cada nodo de la capa de salida\footnote{Recordemos que a esta función también es habitual llamarla función objetivo o función de pérdida (\textit{loss}).}, así como su gradiente, \mip{loss_grad}, de la última capa, y luego mediante un bucle \mip{for} recorremos en forma inversa la lista que contiene cada capa  de la red, invocando el método \mip{backward} de cada capa que propaga hacia atrás los gradientes y actualiza los pesos y sesgos en las capas del tipo \mip{Dense} (las capas \mip{ReLU} no contienen parámetros para optimizar, ya que simplemente implementan la función no lineal de activación). Este método devuelve el valor medio de las funciones de costo de todos los nodos de la última capa.

\pyfile[firstline=148, lastline=169]{Chapters/machine_learning/code/nn-mnist.py}

Por último, agregamos los métodos \mip{dump} y \mip{load}. El primero recibe como argumento una cadena que será el nombre del archivo donde se guarda la instancia de la clase \mip{Network} que contiene todos los parámetros luego del entrenamiento, de forma de poder recuperarlos después con el método \mip{load} y poder utilizar la red sin tener la necesidad de pasar nuevamente por el costoso proceso de entrenamiento:

\pyfile[firstline=171, lastline=180]{Chapters/machine_learning/code/nn-mnist.py}

Usamos el decorador \mip{@classmethod} en \mip{load} de forma de poder instanciar objetos de la clase \mip{Network} directamente a partir de la estructura de la red y los valores de los parámetros almacenados en \mip{filepath} (ver la sección \ref{sec:ntiDecoradores}).

El método definido a continuación, \mip{get_minibatches}, implementa la división del conjunto completo de entrenamiento en pequeñas tandas que permiten acelerar el cálculo, a partir de estimar el gradiente de la función de costo con muestras más pequeñas del conjunto completo $(X, Y)$. Recibe como argumentos las entradas $X$ (\mip{inputs}), las etiquetas $Y$ (\mip{tagets}), el tamaño de la tanda de datos a utilizar en cada etapa de entrenamiento, y una variable booleana \mip{shuffle} que si tiene el valor \mip{True}, realiza una permutación aleatoria de los índices de ambos conjuntos de modo de acceder aleatoriamente a estos datos. Esta función está implementada a modo de generador, que va produciendo estos los índices a medida que se van requiriendo:

\pyfile[firstline=183, lastline=192]{Chapters/machine_learning/code/nn-mnist.py}

La función \mip{train} es la que realiza el entrenamiento de la red y muestra el grado de precisión que obtiene a medida que progresa. Comienza cargando los datos de las entradas y las etiquetas desde un archivo, y separa estos datos en un conjunto que se utilizará para el entrenamiento (\mip{X_train} y \mip{Y_train}) de otros que se utilizarán como validación (\mip{X_val}, \mip{y_val}), que contienen solo un sexto del total de los datos. Esta validación será útil para cuantificar el desempeño de la red prediciendo a partir de datos que no fueron utilizados durante la etapa de entrenamiento:

\pyfile[firstline=195, lastline=200]{Chapters/machine_learning/code/nn-mnist.py}

Luego instanciamos un objeto de la clase \mip{Network}, como una secuencia de una capa \mip{Dense} cuya entrada tiene la misma dimensión que los datos de entrada $X$ (en este caso, un array de $28 \mul 28 = 784$ elementos) conectados a 100 nodos, la segunda capa es la capa ReLU que recibe la salida de las activaciones de la capa anterior y calcula las correspondientes funciones de activación, luego otra capa \mip{Dense}, ahora con 200 nodos, su correspondiente capa ReLU, y la capa final \mip{Dense} con las 10 unidades que generan el vector logit:

\pyfile[firstline=202, lastline=208]{Chapters/machine_learning/code/nn-mnist.py}

A continuación creamos dos listas vacías en las que iremos guardando los resultados de las precisiones obtenidas en cada época de entrenamiento (recordemos que una época consiste en recorrer todos los datos de entrenamiento mediante minibatches), y luego generamos el entrenamiento propiamente dicho en un número fijo de 25 épocas, informando el progreso de la función junto con las precisiones obtenidas en el conjunto de entrenamiento y el de validación, entendiendo estas precisiones como el número medio de aciertos de la red en ambos casos. Al finalizar el recorrido por las épocas, guardamos en un archivo la red entrenada y generamos un gráfico que muestra la evolución de las precisiones obtenidas en los conjuntos de entrenamiento y validación.

\pyfile[firstline=210, lastline=235]{Chapters/machine_learning/code/nn-mnist.py}

La función \mip{show_images} tiene la utilidad de generar imágenes a partir de un conjunto de entrada, con el solo propósito de visualizar dichos datos. Es útil para comprender la tarea de clasificación que le encomendaremos a la red neuronal:

\pyfile[firstline=238, lastline=250]{Chapters/machine_learning/code/nn-mnist.py}

Para tener una estimación cuantitativa del grado de precisión de la red, la función \mip{evaluate} recibe como argumento una cadena (\mip{datasource_path}) que apunta a un archivo que contiene pares de entrada y etiquetas: \mip{X_test} y \mip{Y_test}, respectivamente. Luego instancia una red a partir de un archivo donde se ha guardado previamente una red entrenada y predice los valores correspondientes a las entradas. Finalmente muestra un histograma con los porcentajes de aciertos que ha obtenido, a partir de los valores reales de las etiquetas. 

\pyfile[firstline=253, lastline=279]{Chapters/machine_learning/code/nn-mnist.py}

Por último, generamos un diccionario (\mip{_actions}) que define diversas acciones que se pueden realizar con este código, en forma de pares función/datos. Las claves de este diccionario son las opciones de argumentos en linea de comando con los que se ejecutará el código. Se pueden realizar las siguientes opciones:
\begin{itemize}
    \item \mip{devtrain}: realiza un entrenamiento de la red con un conjunto reducido de datos (\mip{mnist_train_dev.csv}), con el propósito de usarlo para pruebas de depuración del código.
    \item \mip{train}: realiza el entrenamiento sobre el conjunto completo de datos de MNIST (\mip{mnist_train.csv}).
    \item \mip{show}: invoca a la función \mip{show_images} sobre un conjunto reducido de datos para visualizar las imágenes que contiene.
    \item \mip{evaluate}: ejecuta la función \mip{evaluate} sobre el conjunto de prueba \mip{mnist_test.csv} para cuantificar la precisión del entrenamiento realizado sobre la red.
\end{itemize}

\begin{figure}
    \begin{center}
        \includegraphics[scale=0.7]{Chapters/machine_learning/figs/dev_train.png}
    \end{center}
    \caption{Evolución de la precisión en el entrenamiento utilizando el conjunto reducido de datos}
    \label{fig:devtrain}
\end{figure}

Estas opciones se interpretan con el módulo \mip{argparse}, y según el argumento pasado en la linea de órdenes ejecuta cada opción:

\pyfile[firstline=282, lastline=292]{Chapters/machine_learning/code/nn-mnist.py}

Entonces, para el caso de la opción \mip{devtrain}, que contiene solo \num{5000} datos, obtenemos una precisión final de \num{1.0000} para los datos de entrenamiento y \num{0.9388} para los de validación. La evolución del entrenamiento se puede ver en la Figura \ref{fig:devtrain}.

\begin{figure}
    \begin{center}
        \includegraphics[scale=0.7]{Chapters/machine_learning/figs/full-train.png}
    \end{center}
    \caption{Evolución de la precisión en el entrenamiento utilizando el conjunto completo de datos MNIST}
    \label{fig:fulltrain}
\end{figure}

Si ahora realizamos el entrenamiento sobre el conjunto completo de datos de MNIST, usando
\begin{shell}
./nn-mnist.py train
\end{shell}
vemos que la precisión sobre el conjunto de validación mejora hasta el \num{0.9822}, tal como muestra la Figura \ref{fig:fulltrain}.

Por último, evaluaremos la precisión alcanzada por cada dígito del conjunto reducido de datos, con la opción \mip{eval} en la línea de comandos. Tal como muestra la Figura \ref{fig:eval}, vemos que el peor desempeño sucede con la identificación de los dígitos 5 y 4, pero en todos los casos la tasa de aciertos es superior al 97\%.

\begin{figure}
    \begin{center}
        \includegraphics[scale=0.7]{Chapters/machine_learning/figs/eval.png}
    \end{center}
    \caption{Porcentaje de aciertos de la red sobre el conjunto reducido de datos.}
    \label{fig:eval}
\end{figure}

\section{Ejemplo usando Keras}

En la sección anterior implementamos una red \textit{feedforward} con herramientas básicas de Python (NumPy, Matplotlib) con la idea de desmenuzar las operaciones básicas involucradas en el entrenamiento y uso de la red. Afortunadamente existen bibliotecas que permiten abstraer los detalles de cálculo y facilitan la construcción de estructuras complejas con gran variedad de herramientas (distintos nodos de cálculo, funciones de activación, métodos de optimización, etc.), y también la utilización de \textit{hardware} específico para estas aplicaciones (GPUs, TPUs). Estas bibliotecas mantienen un desarrollo muy activo en los últimos años, acompañanado al explosivo crecimiento de las aplicaciones de las técnicas de las redes neuronales de la actualidad.

A continuación abordaremos la identificación de las imágenes del conjunto MNIST por medio de la biblioteca Keras\footnote{\url{https://keras.io/}.}, que a su vez se ejecuta sobre la biblioteca TensorFlow\footnote{\url{https://www.tensorflow.org/}.}, en este caso usando un \textit{notebook} de Jupyter.

Comenzamos importando numpy y fijando una semilla para los números al azar, con el propósito de tener repetibilidad en los cálculos:

\jupynotex[1]{Chapters/machine_learning/code/nn-mnist-keras.ipynb}

En la segunda celda vemos lo simple que resulta acceder a los datos del conjunto MNIST, y además contamos cuántas valores tienen los conjuntos de entrenamiento y de prueba para cada etiqueta:

\jupynotex[2]{Chapters/machine_learning/code/nn-mnist-keras.ipynb}

Para ver cómo son las imágenes que la red tratará de identificar, elegimos 25 muestras aleatoriamente del conjunto de entrenamiento y las visualizamos:

\jupynotex[3, output-image-size=70mm]{Chapters/machine_learning/code/nn-mnist-keras.ipynb}

Al igual que hicimos en la sección anterior, convertimos las etiquetas que tenemos en formato de dígito (0, 1, $\cdots$, 9) en un array codificado en forma \textit{one-hot encoding} (OHE):

\jupynotex[4]{Chapters/machine_learning/code/nn-mnist-keras.ipynb}

En las dos celdas siguientes obtenemos la dimensión del array que representa la imagen de entrada, y adaptamos los arrays de entrada de una imagen cuadrada de bits en el rango \mip{[0, 255]} a un array unidimensional cuyos valores están normalizados:

\jupynotex[5-6]{Chapters/machine_learning/code/nn-mnist-keras.ipynb}

A continuación construimos una red con la misma estructura que usamos en la sección anterior, es decir, una capa de entrada, dos capas densas con activación ReLU con 100 y 200 nodos, respectivamente, y una capa de salida de 10 nodos con activación softmax. Para ello instanciamos un objeto \mip{model} de la clase \mip{Sequential}:

\jupynotex[7]{Chapters/machine_learning/code/nn-mnist-keras.ipynb}

Podemos invocar el método \mip{summary()} para ver los detalles de la red, particularmente la cantidad de parámetros que se ajustarán en la fase de entrenamiento:

\jupynotex[8]{Chapters/machine_learning/code/nn-mnist-keras.ipynb}

Esta celda muestra que tenemos un total de 100710 parámetros que entrenar, que ocupan un total de \mip{393.40} KB. 

En la celda siguiente invocamos el método \mip{compile} sobre el objeto \mip{model}. Este método verifica que la arquitectura del modelo (red) sea válida y que todas las capas estén correctamente conectadas, y prepara el modelo para la fase de entrenamiento en una CPU, GPU o TPU. \mip{compile} recibe tres argumentos: \mip{loss}, que especifica cuál será la función de costo (o pérdida) a utilizar, en este caso entropía cruzada con valores categóricos; \mip{optimizer}, que corresponde al método de optimización, y que para este ejemplo elegimos \mip{adam} (\textit{Adaptative Moments}) que es una variación del método del descenso estocástico del gradiente; y finalmente una métrica, \mip{accuracy}, que es la fracción o porcentaje de predicciones correctas:
 
\jupynotex[9]{Chapters/machine_learning/code/nn-mnist-keras.ipynb}

Ya tenemos entonces todo listo para iniciar el entrenamiento:
 
\jupynotex[10]{Chapters/machine_learning/code/nn-mnist-keras.ipynb}

El método \mip{fit} recibe los arrays de entrada y etiquetas (\mip{x_train} y \mip{y_train}), la cantidad de épocas y el tamaño del batch. Adicionalmente pasamos el argumento \mip{verbose=0} para evitar la salida extensa de esta celda, pero si pasamos el valor por defecto de este parámetro (omitiéndolo por ejemplo), el método mostrará el progreso del entrenamiento informando el tiempo que le toma cada época, la precisión obtenida y el valor de la función de costo, tal como se muestra en la Figura \ref{fig:fit}.

\begin{figure}[t]
\begin{center}
    \includegraphics[scale=0.75]{Chapters/machine_learning/figs/fit.png}
    \caption{Últimas líneas de la salida de ejecución del método fit.}
    \label{fig:fit}
\end{center}
\end{figure}

Una vez entrenada la red, podemos probar cuán eficaz es para predecir las imágenes del conjunto de prueba. Para ello ejecutamos la celda siguiente:
 
\jupynotex[11]{Chapters/machine_learning/code/nn-mnist-keras.ipynb}

Vemos que la tasa de aciertos alcanza el 98\%, muy similar a la precisión que alcanzamos con el modelo de la sección anterior. Una descripción más completa que muestra el desempeño de la red la da la matriz de confusión. Esta matriz representa la cantidad de aciertos para cada clase o etiqueta, así como los ``desaciertos'' al predecir etiquetas erróneas. En la celdas siguientes definimos una función que realiza el gràfico de la matriz de confusion (tomada de la web de scikit-learn, versión 0.18), y obtenemos los valores predichos y verdaderos transformándolos a dígitos desde su representación como arrays OHE:

\jupynotex[12-13]{Chapters/machine_learning/code/nn-mnist-keras.ipynb}

Los valores sobre la diagonal son los aciertos de la red, mientras que los que están fuera de la diagonal muestran cómo se distribuyen los fallos de la red sobre el resto de las etiquetas. Tal como ocurrió en la sección anterior, las imágenes que contienen al número 5 son las que más le cuesta identificar a la red. Si pasamos como argumento \mip{normalize=True} a la función que construye la red, se mostrarán las fracciones de acierto en vez de los números absolutos.

En este ejemplo hemos visto solo las capacidades básicas de Keras, pero la biblioteca ofrece una amplia variedad de herramientas tales como capas \mip{Dropout}, que es una técnica de regularización para reducir el sobreajuste de los datos, funciones de penalización, etc. Además, ofrece la posibilidad de construir otros tipos de redes como convolucionales, o recurrentes.

\section{Lectura recomendadas}
Actualmente se publican numerosos libros que abordan los múltiples aspectos de las redes neuronales. Recomendamos la lectura de los siguientes:
\begin{itemize}
    \item \fullcite{goodfellow2016}.
    \item \fullcite{russel2022}.
\end{itemize}


