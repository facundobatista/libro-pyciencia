
% Copyright 2020-2024 Facundo Batista y Manuel Carlevaro
% Licencia CC BY-NC-SA 4.0
% Para más info visitar https://github.com/facundobatista/libro-pyciencia/

\chapter{Encapsulando código}

\begin{wraptable}{r}{5cm}
\begin{modulesinfo}
\begin{center}
{\small
    \href{https://github.com/facundobatista/libro-pyciencia/tree/master/código/py_encapsulando/}{Código disponible}
}
\end{center}
\end{modulesinfo}
\end{wraptable}

Encapsular código es el acto que nos permite acomodar determinadas líneas de código en alguna estructura para poder reutilizarlas a conveniencia.

La forma más sencilla en Python de lograr esto son las funciones, que es lo primero que estudiaremos en este capítulo. Luego mostraremos las clases, que nos permiten encapsular no sólo el código sino también los objetos sobre los cuales trabaja ese código (abriéndonos las puertas a la Programación Orientada a Objetos), y finalmente hablaremos de módulos y paquetes, que son capas superiores que nos permiten encapsular funciones y clases para usarlas de distintos programas.


\section{Funciones}\label{sec:funciones}

Como mencionábamos al principio del capítulo, la función es la estructura más sencilla para encapsular código. 

Nos permite escribir un bloque de código (con sus estructuras de control de flujo, con sus propios bloques de código, etc) de forma que después podremos ejecutar ese bloque de código ``llamando'' a la función desde cualquier lado.

La forma más sencilla de la estructura de una función es:

\begin{verbatim}
def <nombre>():
    <bloque de código>
\end{verbatim}

Esa estructura, aunque funcional, no nos permite pasarle datos ni obtener un resultado. Pero nos sirve para empezar a familiarizarnos con las funciones. Tenemos entonces un ``nombre'' que es el que usaremos para identificar a la función, y un bloque de código (indentado, como corresponde).

Es importante entender la diferencia entre ``definir'' una función y ``llamar a'' (o ``ejecutar'') una función. En el primer caso solamente hacemos que Python compile la estructura y la tenga en memoria lista para usar, mientras que en el segundo caso es realmente cuando el bloque de código de la función se termina ejecutando.

En el siguiente ejemplo podemos ver primero la definición en sí de la función, y cómo podemos referenciarla con su nombre (en el \mip{print}, o directamente en el intérprete interactivo, y la diferencia fundamental con ejecutar esa función, al final del ejemplo, cuando escribimos el nombre de la función seguida de paréntesis (sin nada entre ellos, en este caso, porque la función no recibe parámetros).

\jupynotex[1-4]{Chapters/py_encapsulando/code/encap-funcs.ipynb}

\begin{info}
En Python cada objeto puede especificar la mejor forma de representarse cuando se llama \mip{str()} o \mip{repr()} al mismo; por default Python mostrará el tipo de objeto y la posición en su memoria interna de objetos.
\end{info}

Tener una función como esa es válido en algunos casos, pero en realidad la mayoría de las veces estaremos pasándole valores a la función y/o recibiendo resultados de la misma.

Para recibir valores, los tenemos que especificar en la definición de la función. Esto se logra de distintas maneras, y es bastante flexible (lo veremos más abajo), pero por ahora, simplificando, digamos que escribimos los nombres con los que haremos referencia a esos valores, y los podremos acceder desde el bloque de código de la función.

En el siguiente ejemplo definimos una función que recibe dos valores (sería un error pasarle uno o tres):

\jupynotex[5-7]{Chapters/py_encapsulando/code/encap-funcs.ipynb}

Hasta ahora la función ejecuta su bloque de código y termina. Por default, la función siempre devuelve \mip{None} al terminar, pero tenemos control sobre eso mediante la declaración \mip{return}.

Podemos poner cualquier cantidad de \mip{return}s en una función. Si el flujo del código pasa por una linea con \mip{return}, la función termina y devuelve lo que allí se indica (no importa si hay otros \mip{return}s en otros lados de la función).

\jupynotex[8-9]{Chapters/py_encapsulando/code/encap-funcs.ipynb}

Prestemos atención al detalle de haber llamado a la función y realizar una asignación con el resultado de esa función, para poder trabajar luego con el mismo.

Tengamos en cuenta que podemos obtener más de un resultado cuando termina una función, para lo cual el \mip{return} soporta que escribamos diferentes valores separados por coma y podemos acceder a esos valores con una asignación múltiple.

\begin{info}
En realidad, a bajo nivel, lo que sucede es que el \mip{return} está devolviendo una tupla con esos valores, y luego en la asignación del resultado entra en juego lo que llamamos \textit{tuple unpacking} \ref{sec:tuplas}.
\end{info}

Ya con un ejemplo más complejo, armemos una función que recibe dos valores y devuelve la multiplicación y la división de ambos números (¡si es posible! si el segundo número es cero devuelve None allí):

\jupynotex[10-16]{Chapters/py_encapsulando/code/encap-funcs.ipynb}

No hay más para explorar por el lado de devolver valores, así que volvamos sobre el otro lado de usar funciones: pasarle parámetros.

Vayamos mostrando las distintas alternativas. El modo más básico es lo que veníamos haciendo, definir algunos parámetros y pasar valores para los mismos. Veamos cuando esto funciona bien, y también los errores que tenemos al no respetar ese ``acuerdo básico'':

\jupynotex[17-20]{Chapters/py_encapsulando/code/encap-funcs.ipynb}

Un detalle básico pero interesante es que hay una correspondencia ordinal entre los parámetros especificados en la definición de la función y los valores que pasamos al llamarla: el \verb|5| va a la \verb|a| y el \verb|6| va a la \verb|b|; es por esto que llamamos ``posicionales'' a estos argumentos (lo vemos también en el mensaje de error en el ejemplo).

Cuando definimos la función podemos especificar que algunos de esos parámetros tengan un valor por default, entonces no va a ser necesario pasarlos cuando llamemos a la función:

\jupynotex[21-24]{Chapters/py_encapsulando/code/encap-funcs.ipynb}

En el ejemplo vemos que si pasamos sólo el valor para \verb|a|, \verb|c| y \verb|b| tienen sus valores por default. En la segunda llamada pasamos valor para \verb|a| y para \verb|b| (de nuevo, porque son posicionales, el primer valor al primer parámetro, etc.), pero no para \verb|c|. Y finalmente, vemos que si les pasamos valores para los tres, no se consideran sus valores por default.

¿Pero cómo haríamos en el ejemplo anterior para pasar un valor a \verb|a| y a \verb|c|, pero no a \verb|b| (y que tome su valor por default)? Para ello nos tendríamos que salir del esquema de parámetros posicionales y empezar a nombrarlos, lo cual es tan sencillo como especificar para qué parámetro queremos que vaya cada valor:

\jupynotex[21,25]{Chapters/py_encapsulando/code/encap-funcs.ipynb}

En este caso vemos que pasamos un \verb|9| que va a \verb|a| (¡posicional!) pero luego especificamos que el \verb|7| va para \verb|c|; a \verb|b| no le terminamos pasando un valor, así que toma su default.

En realidad una vez que nombramos los parámetros, podemos escaparnos totalmente al orden de sus posiciones, más allá que en la definición tengan valores por default o no:

\jupynotex[21,26-27]{Chapters/py_encapsulando/code/encap-funcs.ipynb}

Hasta ahora estamos manejando cantidad de fija de parámetros. Python soporta que en la definición usemos el \mip{*} que consumirá todos aquellos valores que pasemos por posición que no hayan sido tomados todavía:

\jupynotex[28-30]{Chapters/py_encapsulando/code/encap-funcs.ipynb}

En el ejemplo vemos como en la primer llamada los dos valores que pasamos van a los primeros dos parámetros definidos, pero no quedó nada para \verb|c| (entonces es una tupla vacía), mientras que en el segundo caso ``sobraron'' dos valores, entonces \verb|c| si tiene contenido.

También Python nos ofrece el \mip{**}, que de manera similar consumirá todos los nombrados que no hayan encontrado otro lugar:

\jupynotex[31-33]{Chapters/py_encapsulando/code/encap-funcs.ipynb}

Para el caso de \mip{*} la estructura donde Python guarda los argumentos posicionales sobrantes es una tupla, ya que sólo es importante el orden, mientras que para el \mip{**} como tenemos valores y nombres, la estructura útil para guardar eso es el diccionario.

Obviamente se pueden combinar todos los casos que estuvimos viendo hasta recién .

\jupynotex[34-36]{Chapters/py_encapsulando/code/encap-funcs.ipynb}

Todo esto funciona mientras no haya ambigüedades en la definición o en el llamado a la función; en esos casos Python mostrará un mensaje de error indicando el problema.

\jupynotex[37-38]{Chapters/py_encapsulando/code/encap-funcs.ipynb}

Así como podemos usar en la definición el \mip{*} para guardar excedentes posicionales en una tupla y \mip{**} para los excedentes nombrados en un diccionario, podemos usarlos en las llamadas a las funciones para ``desarmar'' una tupla con los valores o un diccionario con los nombres/valores:

\jupynotex[39-41]{Chapters/py_encapsulando/code/encap-funcs.ipynb}

Cabe acotar que no estamos mencionando todos los casos posibles, y que hay más reglas y operadores (como forzar a que los parámetros sean nombrados o posicionales), y algunos detalles más, explicados en profundidad en la referencia del lenguaje \cite{referencia_funciones}.


\subsection{Espacios de nombres}

Cuando explicamos cómo funcionaba Python con sus objetos y nombres (en lugar de variables con valores, ver Sección \ref{sec:pensando-pythonista}), usamos unos diagramas donde a la derecha teníamos los objetos en memoria, y a la izquierda otra zona donde poníamos los nombres. Este espacio reservado para los nombres se llama justamente ``espacio de nombres'' (en inglés \textit{namespace}), y es una zona de memoria donde justamente se guardan los nombres que referencian a los otros objetos.

Traemos esto a colación en esta subsección porque en Python no tenemos solamente un espacio de nombres, sino que pueden haber muchos, y las funciones tienen mucho que ver en eso.

Cuando arranca Python tenemos un espacio de nombre que se conserva hasta que el proceso termina y es accesible desde todos lados: el espacio de nombre ``global''. Por otro lado, cada vez que ejecutamos una función, se crea otro espacio de nombres, ``local'' a la función, que permanecerá activo mientras las función se está ejecutando y desaparecerá cuando la misma termine.

Tenemos que tener en cuenta que lo que se destruye al terminar la función es el espacio de nombre, no los objetos referenciados por los mismos. Claro, algunos objetos quedarán sin referencia luego de que el espacio de nombre desaparezca (y de esos se encarga la administración automática de memoria de Python), pero puede ser que otros objetos estén referenciados de otros lados, y sigan vivos.

Veamos un ejemplo sencillo:

\jupynotex[42-44]{Chapters/py_encapsulando/code/encap-funcs.ipynb}

Analicémoslo en detalle, por partes. Lo primero que tenemos es una definición de una función (que todavía no ejecutamos, claro). Luego le ponemos nombre a dos enteros (\verb|x| e \verb|y|), que usamos para llamar a la función. En \textit{ese} momento se ejecuta la función, que nos devuelve 15.

Si vamos a la ejecución de la función, vemos que esos dos enteros los recibe en dos parámetros que llama \verb|a| y \verb|b|, realiza un cálculo y devuelve ese valor. Como parte del procesamiento, la función también define un nombre \verb|x|, pero este se define en el espacio de nombres \textit{local} de la función (igual que \verb|a| y \verb|b|, para el caso).

La \verb|x| definida en el espacio de nombres local apunta al entero 15, y luego de ejecutar la función vemos que, afuera, \verb|x| sigue apuntando al 3 original. Esto es porque afuera estamos usando el espacio de nombres global, no se nos mezcla con el espacio de nombres local de la función.

Es importante entender la diferencia entre ``definir'' un nombre en un espacio de nombres, y tener ``acceso'' a ese nombre (también decimos ``ver'' ese nombre, en inglés se usa \textit{scope}). Veamos el siguiente ejemplo para resaltar esta diferencia:

\jupynotex[45-49]{Chapters/py_encapsulando/code/encap-funcs.ipynb}

Arrancamos definiendo una función (que veremos en detalle a continuación, cuando la ejecutemos), y luego se definen en el espacio de nombres global una \verb|x| apuntando a un 8 y una \verb|y| apuntando a un 9.

Cuando ejecutamos la función, esta primero define una \verb|y| apuntando a un 2 y una \verb|z| apuntando a un 3 (en ambos casos, en el espacio de nombres local de la función), y luego hace un print de tres nombres: para \verb|x| e \verb|y| es simple, porque está mostrando lo que encuentra en el espacio de nombres local, pero \verb|z| nos puede sorprender. 

Es aquí donde tenemos que entender que a nivel de visibilidad, desde adentro de la función Python intenta resolver el nombre primero buscando en el espacio de nombres local, y luego si no la encuentra allí busca en el espacio de nombres global. Esta secuencia es importante, porque eso determina que el \verb|y| que encuentra es el que apunta al 2 (¡no al 9!), y para \verb|z| que no está local pero si global, igual la encuentra.

Por otro lado, desde afuera de la función no tenemos visibilidad a su espacio de nombres, por eso cuando al final queremos ver el valor de \verb|z| nos da error de nombre, porque \verb|z| no está definida en el espacio de nombres global (y es en el único en que busca).

Un detalle importante es que como desde adentro de la función tenemos visibilidad sobre los objetos del espacio de nombres global, si los objetos son mutables podremos modificarlos:

\jupynotex[50-53]{Chapters/py_encapsulando/code/encap-funcs.ipynb}

Aunque podría considerarse una mala práctica de programación (porque la función nos está cambiando objetos que viven fuera de ella), en algunos casos es útil y muy ventajoso poder hacer eso. ¡Usar con precaución!


\subsection{Generadores}

Los generadores son un tipo particular de objeto que cuando los iteramos nos dan elementos, pero no los tenían de antes. Los van generando en el momento. Un ejemplo integrado en Python es el \mip{range}. Si hacemos \mip{range(10 ** 100)} obtenemos un objeto que si le pedimos, nos dará enteros entre 0 y 10\textsuperscript{100} - 1, pero obviamente no preparó todos esos números en el momento. Los irá \textit{generando}.

Se usan mucho en Python porque optimizan el uso de memoria y mejoran el rendimiento general. Veamos el siguiente ejemplo que aunque muy simple, muestra una optimización clara que repetida por varios rincones del lenguaje hacen una diferencia importante:

\jupynotex[54]{Chapters/py_encapsulando/code/encap-funcs.ipynb}

El ejemplo suma los números del 0 al 9, generados por el \mip{range}. Si \mip{range} (en vez de funcionar como generador) armara una lista con los números del 0 al 9, el efecto sería exactamente el mismo, con el detalle que como parte del proceso, se construyó una lista con todos los números en memoria simultáneamente, que luego fue consumida por el \mip{sum}. Esa lista no sirvió para nada, en realidad, sólo ocupó memoria y tiempo para su creación/administración.

Hay distintas formas de construir generadores en Python, pero una de las más simples es armar una ``función generadora''. Parece una función normal con la excepción que dentro de su bloque de código usa la declaración \mip{yield}, que justamente le cambia el comportamiento.

¿Recuerdan que dijimos que las funciones cuando las llamamos se ejecutan hasta que terminan, destruyendo su espacio de nombres local, y que cuando las volvemos a llamar vuelven a ejecutarse desde el principio? Bueno, justamente las funciones generadoras cambian ese comportamiento. Cuando llamamos a la función nos devuelve un generador. Cuando le vamos pidiendo elementos a ese generador lo que va a hacer es ejecutar esa función hasta que llega a un \mip{yield}, devolviéndonos lo que allí se indica, ``pausando'' la ejecución de ese código. Y cuando le pidamos el próximo elemento al generador, ese código ``se despertará'' en el punto en que estaba y continuará su ejecución hasta que termine o encuentre otro \mip{yield}.

Para ver esto en un ejemplo, primero hagamos una versión casera y recortada del \mip{range} con una función clásica, para poder comparar ambos códigos.

\jupynotex[55-57]{Chapters/py_encapsulando/code/encap-funcs.ipynb}

En esta función vemos lo que mencionábamos arriba. La función genera una lista con los números, luego el \mip{sum} la consume sumando esos números y produce el 45 como resultado. No sólo la lista es innecesaria, también mantener todos los números al mismo tiempo en memoria sólo para sumarlos es un desperdicio de recursos. Esto es obviamente un factor si tenemos una lista muy grande, pero tampoco hay que desestimar la situación con estructuras pequeñas, porque cualquier necesidad de memoria puede disparar que el proceso que estamos ejecutando tenga que salir a pedirle memoria al sistema operativo, y eso siempre es caro.

Convirtamos la función de arriba en generadora.

\jupynotex[58-62]{Chapters/py_encapsulando/code/encap-funcs.ipynb}

La estructura definida es muy similar, pero notemos que no tenemos la estructura interna \texttt{nros} (porque no estamos creando esa lista), y que aparece el famoso \mip{yield}.

Cuando ejecutamos esta función generadora, realmente no se empieza a ejecutar el bloque de código, sino que obtenemos el objeto generador en sí, como mostramos en el ejemplo. Al hacer el primer \mip{next} se empieza a ejecutar el código, hasta que llega al \mip{yield}, allí devuelve el valor que teníamos en \verb|n| (el \verb|0|) y la ejecución del código queda suspendida (ya que el control lo tenemos nosotros en el intérprete interactivo). Cuando hacemos el segundo \mip{next}, la ejecución no arranca desde el principio, sino que continua desde donde estaba, sumándole \verb|1| a \verb|n|, luego vuelve a evaluar la expresión del \mip{while} y llega nuevamente al \mip{yield}, devolviéndonos ahora el \verb|1|. 

Si siguiéramos pidiéndole números con el \mip{next}, los seguiríamos obteniendo hasta que la expresión del \mip{while} de falso, y en ese caso vemos que se termina la función. Como es una función generadora, cuando sale de la función en realidad se genera la excepción \mip{StopIteration} que es la que usa Python para indicar que no hay más ítems para iterar. Esto nos permite integrar a estos generadores en todas las estructuras normales de Python.

Finalmente entonces, usamos en el \mip{sum} la función generadora que armamos, que vemos que nos devuelve el mismo resultado que con la estructura clásica, pero sin construir la lista intermedia.

También podemos aplicar este concepto de ``generador'' a las comprensiones de listas \ref{sec:for}, armando directamente ``comprensiones generadoras'', usando paréntesis en lugar de corchetes

\jupynotex[63]{Chapters/py_encapsulando/code/encap-funcs.ipynb}

Incluso podemos obviar esos paréntesis cuando tenemos a la expresión generadora dentro de una llamada a función (porque los dobles paréntesis son superfluos en Python).

Veamos un simple ejemplo donde sumamos los cuadrados del 0 al 9 de dos formas distintas. 

\jupynotex[64-65]{Chapters/py_encapsulando/code/encap-funcs.ipynb}

En ambos casos arrancamos con \mip{range} (que es generadora), pero en el primero armamos una lista intermedia con los cuadrados (notemos los corchetes que arman la compresión de listas), mientras que en el segundo tenemos una comprensión generadora (no hace falta poner los paréntesis, ya que aprovechamos los de alrededor.

Para el \mip{sum} es exactamente lo mismo, y tenemos el mismo resultado, pero el segundo caso es más rápido y hasta más legible y conciso.


\section{Clases}\label{sec:clases}

Las ``clases'' son una forma de encapsular código junto a los objetos que son manejados por ese código.

Aunque suena simple, realmente esto nos permite separar en distintas estructuras los distintos objetos que necesitamos manejar con el código para procesarlos, lo cual nos permite modelar eficientemente la realidad que estamos tratando de representar, abriéndonos las puertas de la Programación Orientada a Objetos (en adelante ``POO'').

En este libro mostraremos el funcionamiento básico de las clases, la definición de su estructura, qué implica instanciarlas y las bases del funcionamiento de los objetos que obtenemos, pero no pretendemos enseñar POO en un capítulo, ya que es un tema para todo un libro (¡o más de uno!).

Entonces la idea es que podamos leer y entender código que usa clases, e incluso construir algunas sencillas, sin pretender desbloquear todo su potencial.

La estructura básica de una clase es extremadamente simple:

\begin{verbatim}
class <nombre>:
    <bloque de código>
\end{verbatim}

Con eso ya armamos una clase con el nombre que queramos, y tenemos un bloque de código para continuar. Como con las funciones, las clases nos crean un espacio de nombres diferente, y allí es que empezaremos a agregar código que luego utilizaremos más adelante.

Armemos un ejemplo con más elementos, para empezar a explicarlos:

\jupynotex[1-4]{Chapters/py_encapsulando/code/encap-clases.ipynb}

En el bloque de código definimos una variable y una función, y luego las usamos. Veamos que hicimos \mip{Foo.a} y \mip{Foo.f()}, porque tanto ``a'' como ``f'' no están en el espacio de nombres global, sino en el de la clase (y como con los módulos, cuando hacíamos \mip{math.sqrt(2)} \ref{sub:intromods}, usamos el punto para indicar que estamos usando un nombre de ``adentro'' de otro objeto). Entonces, es claro que tanto ``a'' como ``f'' están adentro de la clase. 

Lo que es raro en ese ejemplo es como estamos usando la clase. En realidad el uso normal de una clase es para generar objetos, como es regla en la POO. Es más, como ya estamos metiéndonos en ese mundillo, adoptemos dos términos que son de uso genérico allí y que vamos a encontrar en muchos textos. Las variables dentro de las clases y objetos las llamaremos ``atributos'', mientras que las funciones que definimos allí adentro las llamaremos ``métodos''. Entonces, de acuerdo con esta nueva terminología, diremos que tenemos ``una clase Foo con un atributo a y un método f''.

Ahora hagamos el último salto y armemos una clase que tiene sentido ser usada para instanciar objetos.

\jupynotex[5]{Chapters/py_encapsulando/code/encap-clases.ipynb}

Epa, ¡cuantas cosas nuevas! Vayamos entendiéndolas por partes, viendo cómo encaja en este uso distinto que mencionamos arriba. 

Las clases, en el paradigma de POO, son las estructuras que encapsulan el código para procesar determinada información, junto a dicha información. Y funcionan como plantillas, que nos darán distintos objetos cada vez que \textit{instanciemos} la clase. Estos objetos serán del mismo tipo (el tipo de los objetos es la clase en sí), y por lo tanto el código encapsulado será el mismo, aunque ese código procesará la distinta información que tendremos en cada objeto.

En nuestro ejemplo tenemos una clase TriánguloRectángulo, donde encapsulamos un código (cómo calcular la hipotenusa a partir de los catetos) junto a la información en sí (los catetos). Si queremos trabajar con distintos triángulos, obviamente tendremos una variedad de pares de catetos, pero en todos los casos la forma de calcular la hipotenusa es la misma; esto está en linea con la filosofía de la POO de que estos objetos modelan y representan nuestra realidad.

Armemos entonces dos triángulos, para experimentar y seguir entendiendo ese código (sin repetir aquí la definición de la clase, por brevedad):

\jupynotex[6-9]{Chapters/py_encapsulando/code/encap-clases.ipynb}

Vemos que al nombre de la clase le estamos agregando paréntesis, como hacemos con las funciones cuando las ejecutamos. Aquí es similar, pero a la clase la estamos \textit{instanciando}, lo que nos devuelve un ``objeto del tipo TriánguloRectángulo'', que guardamos en t1 (y luego hacemos lo mismo con t2).

Cuando le decimos al intérprete interactivo que nos muestre esos objetos, vemos que nos dice que son del tipo TriánguloRectángulo y nos dice que están en posiciones de memoria distintas (con lo cual podemos deducir que son dos objetos distintos). Es más, cuando nos fijamos el valor de \verb|cateto1| de ambos objetos vemos que obtenemos distintos valores (¡son distintos objetos!), cada uno teniendo el primer valor que pasamos cuando instanciamos la clase. 

¿Cómo sucedió eso? Si volvemos a la definición de la clase, vemos que allí teníamos un método con un nombre especial, \mip{__init__}. Este método se ejecuta automáticamente cuando instanciamos la clase donde está definido. Entonces, cuando hicimos \mip{TriánguloRectángulo(4, 5)} se instanció la clase y se ejecutó ese método de inicialización, pasándole justamente estos valores que indicamos nosotros.

\begin{info}
Los métodos especiales son un conjunto de métodos predefinidos, con comportamientos específicos definidos en el lenguaje mismo \cite{metodos_especiales}, que Python utiliza para interactuar con los objetos en todo nivel, por ejemplo llamando a \mip{__init__} para inicializar una clase, o \mip{__iter__} cuando recorremos un objeto con el {for}.
\end{info}

Pero si prestamos un poco más de atención veremos que en su definición \mip{__init__} declara que tiene que recibir 3 parámetros (\verb|self|, \verb|cateto1| y \verb|cateto2|), mientras que nosotros estamos pasando solamente dos. Es que para todo lo que es métodos en las clases, Python inserta automáticamente como primer parámetro al objeto mismo que estamos manejando, al que por convención llamamos \mip{self}.

Y allí vemos que el cuerpo del método \mip{__init__} lo que hace es crear los nombres \verb|cateto1| y \verb|cateto2| \textit{adentro del objeto}, apuntando a los objetos recibidos. Entonces, cuando instanciamos TriánguloRectángulo la primera vez, pasamos los valores 4 y 5 y en ese caso el \mip{self} es el objeto que terminamos llamando t1 y guarda esos dos valores, y cuando la instanciamos por segunda vez, pasando los valores 10 y 1, \mip{self} es el objeto que terminamos llamando t2, con estos dos otros valores en vez.

Usemos ahora el otro método que tenemos definido:

\jupynotex[10-11]{Chapters/py_encapsulando/code/encap-clases.ipynb}

Vemos que lo ejecutamos desde t1 y t2, y no pasamos ningún parámetro. Pero en la definición, arriba en la clase, recibe el parámetro \mip{self}. Estamos en la misma situación que antes: como es el método de una clase, cuando lo ejecutamos desde una instancia de la clase Python insertará el objeto mismo como parámetro, que oportunamente usamos para la cuenta: cuando hacemos por ejemplo \mip{self.cateto1 ** 2} estamos usando el nombre \verb|cateto1| de adentro del objeto, que para t1 apuntará a 4 y para t2 apuntará a 10. 

Al final de cuentas, lo que tenemos es un determinado código que se aplica a los valores que tiene cada instancia de esa clase. Exactamente el concepto con el que arrancamos arriba toda la explicación de clases, objetos, y POO.

Otro concepto muy útil cuando queremos modelar la realidad usando objetos es el de ``herencia'', generalmente utilizado cuando tenemos algunos comportamientos que son comunes a distintos tipos de objetos. Lo normal es encontrar una clase ``padre'' y muchas clases ``hijas'', pero Python soporta herencia múltiple, aunque es de uso más raro.

Cuando definimos una clase, entonces, si queremos que herede de otra incluiremos a esta última entre paréntesis en la definición de la primera. No vamos a entrar en detalle en este libro sobre cómo explotar todas las características del concepto de herencia, pero lo mencionamos para poder reconocer su uso cuando lo encontremos en algún código.

Particularmente, un caso que incluso ya mostramos en la Sección \ref{sec:excepciones} es cuando creamos una excepción propia, que para que sea justamente una excepción utilizable por el lenguaje, la definimos heredando su comportamiento de alguna excepción integrada en el lenguaje:

\jupynotex[12]{Chapters/py_encapsulando/code/encap-clases.ipynb}

Para profundizar más sobre la utilización de clases pueden seguir leyendo sobre este tema en el capítulo específico de clases \ref{ch:clasesavanz}.


\section{Módulos}\label{sec:modulos}

Como vimos hasta ahora, las formas más comunes de encapsular código son las funciones y las clases. Entonces, pondremos código adentro de esas estructuras, que usaremos desde distintos puntos de nuestro programa. El paso natural siguiente es el de agrupar algunas de esas funciones y clases de nuestro programa en ``módulos'', de manera de poder importar esos módulos de distintos lugares y tener acceso a las funciones y clases (y cualquier otra estructura) que pongamos allí.

Los módulos no son más que archivos de Python, sin tener casi ninguna otra restricción. Mostremos un ejemplo para ver lo sencillo que es crear y usar un nuevo módulo de Python.

Pongamos el siguiente código en un archivo, al que llamaremos \texttt{perimetros.py}:

\pyfile{Chapters/py_encapsulando/code/perimetros.py}

Vemos en el ejemplo que además de la definición de esas funciones tenemos otras líneas de código a ``nivel de módulo'', como el \mip{import} o el cálculo para tener ``dos $\pi$'' a mano. Todo el código del módulo se ejecutará cuando lo importemos; se importará math, se definirá \texttt{dos\_pi}, y también se definirán las dos funciones que usaremos luego.

Para usar ese módulo, como es el caso con cualquier otro módulo, sólo tenemos que importarlo. Entonces, en el mismo directorio que grabamos \texttt{perimetros.py}, abramos un intérprete interactivo y hagamos:

\begin{py}  
>>> import perimetros
>>> perimetros.círculo(12)
75.39822368615503
\end{py}

Necesitamos que el módulo esté en el mismo directorio donde abrimos el intérprete interactivo porque cuando hacemos el \mip{import} Python va a buscar el nombre que indicamos en una serie de directorios, entre ellos el actual del proceso. Claro, podríamos poner nuestro módulo en algunos de los otros directorios donde Python busca, pero ello ya implicaría ``instalar'' nuestro módulo.

La otra opción para facilitar que podamos encontrar nuestro módulo es directamente agregar el directorio que necesitemos en la lista de lugares donde Python busca. Esto lo podemos hacer a través de la variable de entorno \texttt{PYTHONPATH} del sistema operativo, o incluso desde adentro de Python modificando \mip{sys.path}.

Volviendo al ejemplo donde usamos nuestro módulo, vemos que lo importamos usando su nombre, y luego podemos acceder a su contenido usando el \mip{.}, como ya vimos en otros casos. Esta no es la única manera de importar el módulo, también podemos utilizar otra forma en la que en vez de quedarnos con el nombre del módulo para trabajar, nos traemos directamente los nombres de las estructuras internas:

\begin{py}  
>>> from perimetros import círculo
>>> círculo(12)
75.39822368615503
\end{py}

Tengamos en cuenta que no cambia nada a la hora de importar el módulo en sí, no es más rápido, ni usa menos memoria, ni ejecuta menos código: la única diferencia es con qué nombres nos quedamos para trabajar.

Bien, ya sabemos agrupar nuestro código en módulos. El próximo paso es agrupar esos módulos en un próximo nivel.

La estructura para agrupar módulos se llama ``paquete'', que no son más que directorios.

Para probar esto, creemos un directorio \texttt{geom} y pongamos nuestro archivo \texttt{perimetros.py} allí. Eso es todo; ahora para importar ese módulo tenemos que especificar el paquete. Veamos las distintas formas de terminar ejecutando la función \texttt{círculo} en esta nueva situación: indicando el paquete y el módulo, trayendo el módulo del paquete, y trayendo directamente la función (de nuevo, en los tres casos el módulo se importa exactamente igual, sólo cambia con qué nos quedamos para trabajar).

\begin{py}  
>>> import geom.perimetros
>>> geom.perimetros.círculo(12)
75.39822368615503
>>> from geom import perimetros
>>> perimetros.círculo(12)
75.39822368615503
>>> from geom.perimetros import círculo
>>> círculo(12)
75.39822368615503
\end{py}

Si en un directorio/paquete ponemos un archivo con el nombre especial \texttt{\_\_init\_\_.py}, este archivo se ejecutará cuando importemos el paquete o cualquier módulo de ese paquete, lo cual es muy práctico para cualquier tipo de inicialización que necesitemos realizar.
